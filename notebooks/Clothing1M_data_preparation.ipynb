{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clothing 1M data download and preparation\n",
    "\n",
    "## Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "links = \"\"\"https://drive.google.com/u/1/uc?id=0B67_d0rLRTQYdFpwZ09fNzF3NjA&export=download\n",
    "https://drive.google.com/u/1/uc?id=0B67_d0rLRTQYb3ppZEQ0UnNwUmM&export=download\n",
    "https://drive.google.com/u/1/uc?id=0B67_d0rLRTQYTTdOWVdib0x2cVU&export=download\n",
    "https://drive.google.com/u/1/uc?id=0B67_d0rLRTQYN2ZvUzNFUkQ5ZGM&export=download\n",
    "https://drive.google.com/u/1/uc?id=0B67_d0rLRTQYblNlYXhKVWNYVFU&export=download\n",
    "https://drive.google.com/u/1/uc?id=0B67_d0rLRTQYWDAzWkVCWmhqYjg&export=download\n",
    "https://drive.google.com/u/1/uc?id=0B67_d0rLRTQYX3lnY2ZIcERVOGM&export=download\n",
    "https://drive.google.com/u/1/uc?id=0B67_d0rLRTQYTjZsUkhaU3hzZTA&export=download\n",
    "https://drive.google.com/u/1/uc?id=0B67_d0rLRTQYVW5QT0l2U2JJSmc&export=download\n",
    "https://drive.google.com/u/1/uc?id=0B67_d0rLRTQYZTlaYnBaNHg4dmM&export=download\n",
    "https://drive.google.com/u/1/uc?id=0B67_d0rLRTQYUWFyeHVfX0s3QzQ&export=download\n",
    "\"\"\"\n",
    "\n",
    "start = \"https://drive.google.com/u/1/uc?id=\"\n",
    "end = \"export=download\\n\"\n",
    "\n",
    "file_ids = links.replace(start, \"\").replace(end, \"\").split(\"&\")[:-1]\n",
    "file_ids\n",
    "\n",
    "f = open(\"download.txt\", \"r\")\n",
    "target_url = f.read()\n",
    "target_url\n",
    "\n",
    "i = 1\n",
    "file_id = file_ids[i]\n",
    "print(file_id, \"\\n\\n\")\n",
    "filename = f\"{i}.tar\"\n",
    "final_url = target_url.replace(\"FILE_ID\", file_id).replace(\"FILE_NAME\", filename)\n",
    "print(final_url)\n",
    "\n",
    "i = 10\n",
    "if i ==10:\n",
    "    file_id = file_ids[i]\n",
    "    filename = f\"annotations.tar\"\n",
    "    final_url = target_url.replace(\"FILE_ID\", file_id).replace(\"FILE_NAME\", filename)\n",
    "    print(final_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import itertools\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import models\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as npn\n",
    "import torchvision\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import utils\n",
    "import warnings\n",
    "from PIL import Image\n",
    "import h5py\n",
    "\n",
    "plt.ion()\n",
    "plt.show()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../../datasets/clothing1M\"\n",
    "dataset_name = \"clothing1M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f\"{path}/annotations/category_names_eng.txt\"\n",
    "class_names = {}\n",
    "with open(fn, 'r') as rf:\n",
    "    for i, line in enumerate (rf.readlines()):\n",
    "        class_names[i] = line.rstrip()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f\"{path}/annotations/clean_label_kv.txt\"\n",
    "\n",
    "df = pd.read_csv(fn, sep=\" \", header= None)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"class balance clean data\")\n",
    "df[1].value_counts().plot(kind = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train, test, val splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=6,shuffle=True, random_state=1) # generate folds\n",
    "X = np.arange(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, (train_index, val_index) in enumerate(skf.split(X, df[1].values)):\n",
    "    break\n",
    "print(len(train_index), len(val_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[train_index].reset_index(drop=True).to_pickle(f\"{path}/annotations/clean_train.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create small test for knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[val_index].reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3,shuffle=True, random_state=1) # generate folds\n",
    "X = np.arange(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, (val_index, test_index) in enumerate(skf.split(X, df[1].values)):\n",
    "    break\n",
    "len(val_index), len(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[val_index].reset_index(drop=True).to_pickle(f\"{path}/annotations/clean_val.pkl\")\n",
    "df.iloc[test_index].reset_index(drop=True).to_pickle(f\"{path}/annotations/clean_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in [ \"test\", \"val\", \"train\",]:\n",
    "    df = pd.read_pickle(f\"{path}/annotations/clean_{name}.pkl\")\n",
    "    with h5py.File(f\"{path}/annotations/clean_{name}.hdf5\", 'a') as h:\n",
    "        # Create dataset inside HDF5 file to store images\n",
    "        images = h.create_dataset('images', (df.shape[0], img_size, img_size, 3), dtype='uint8')\n",
    "        print(\"\\nReading  images and captions, storing to file...\\n\" )\n",
    "\n",
    "        for i in tqdm(range(df.shape[0])):\n",
    "            img_path, _ = df.iloc[i].values\n",
    "            image = Image.open(f\"{path}/{img_path}\")\n",
    "            image = image.resize((img_size, img_size), Image.ANTIALIAS)\n",
    "            images[i] = np.asarray(image)  # Save image to HDF5 file\n",
    "\n",
    "        labels = df[1].values\n",
    "        print(f\"Min label {min(labels)}, Max {max(labels)}\")\n",
    "        np.save(f\"{path}/annotations/clean_{name}.npy\", labels)\n",
    "    h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
