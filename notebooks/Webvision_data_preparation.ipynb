{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clothing 1M data download and preparation\n",
    "\n",
    "## Data download\n",
    "\n",
    "Data can be downloaded from: https://data.vision.ee.ethz.ch/cvl/webvision/download.html   \n",
    "\n",
    "\n",
    "e.g. wget https://data.vision.ee.ethz.ch/cvl/webvision/flickr_resized_256.tar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import itertools\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import models\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as npn\n",
    "import torchvision\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import utils\n",
    "import warnings\n",
    "from PIL import Image\n",
    "import h5py\n",
    "\n",
    "\n",
    "import utils\n",
    "import warnings\n",
    "\n",
    "plt.ion()\n",
    "plt.show()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../../datasets/webvision\"\n",
    "\n",
    "dataset_name = \"webvision\"\n",
    "google_only = True\n",
    "\n",
    "fn = f\"{path}/info/val_filelist.txt\"\n",
    "\n",
    "df = pd.read_csv(fn, sep=\" \", header= None)\n",
    "print(df.shape, len(df[1].unique()))\n",
    "df[0] = df[0].apply(lambda x: f\"val_images_256/{x}\") # add folder path\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google = f\"{path}/info/train_filelist_google.txt\"\n",
    "flicker = f\"{path}/info/train_filelist_flickr.txt\"\n",
    "if google_only:\n",
    "    df_noisy =pd.read_csv(google, sep=\" \", header=None) # use only google data\n",
    "else:\n",
    "    df_noisy = pd.concat([\n",
    "        pd.read_csv(google, sep=\" \", header=None),\n",
    "        pd.read_csv(flicker, sep=\" \", header=None)\n",
    "    ], ignore_index = True)\n",
    "\n",
    "\n",
    "print(df_noisy.shape)\n",
    "df_noisy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the number of classes to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 50\n",
    "\n",
    "df = df[df[1] <nb_classes]\n",
    "\n",
    "df_noisy = df_noisy[df_noisy[1] <nb_classes]\n",
    "\n",
    "df.reset_index(drop=True).to_pickle(f\"{path}/info/test_{nb_classes}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train - val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=20,shuffle=True, random_state=1) # generate folds\n",
    "X = np.arange(df_noisy.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, (train_index, val_index) in enumerate(skf.split(X, df_noisy[1].values)):\n",
    "    break\n",
    "\n",
    "len(train_index), len(val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noisy.iloc[val_index].reset_index(drop=True).to_pickle(f\"{path}/info/val_{nb_classes}.pkl\")\n",
    "df_noisy.iloc[train_index].reset_index(drop=True).to_pickle(f\"{path}/info/train_{nb_classes}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path, img_class = df.iloc[0].values\n",
    "img_path, img_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot randomly selected images per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(50):\n",
    "    plt.figure(figsize = (7, 3))\n",
    "    for j in range(3):\n",
    "        plt.subplot(1, 3, j+1)\n",
    "        ds = df[df[1] ==i ].reset_index(drop=True).copy()\n",
    "        img_path, img_class  = ds.iloc[np.random.randint(0, len(ds))].values\n",
    "        full_img_path = f\"{path}/{img_path}\"\n",
    "        img = Image.open(full_img_path)\n",
    "        plt.title(f\"Class {i}\")\n",
    "        plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "nb_classes= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in [\"val\", \"test\", \"train\"]:\n",
    "    df = pd.read_pickle(f\"{path}/info/{name}_{nb_classes}.pkl\")\n",
    "    if google_only:\n",
    "        uid = f\"{path}/info/google{name}_{nb_classes}_{img_size}\"\n",
    "    else:\n",
    "        uid = f\"{path}/info/{name}_{nb_classes}_{img_size}\"\n",
    "    with h5py.File(f\"{uid}.hdf5\", 'a') as h:\n",
    "        # Create dataset inside HDF5 file to store images\n",
    "        images = h.create_dataset('images',\n",
    "                                  (df.shape[0], img_size, img_size, 3),\n",
    "                                  dtype='uint8')\n",
    "        print(\n",
    "            f\"\\n {name} : Reading {df.shape} images and captions, storing to file...\\n\"\n",
    "        )\n",
    "\n",
    "        for i in tqdm(range(df.shape[0])):\n",
    "            img_path, _ = df.iloc[i].values\n",
    "            image = Image.open(f\"{path}/{img_path}\")\n",
    "            image = image.resize((img_size, img_size), Image.ANTIALIAS)\n",
    "            images[i] = np.asarray(image)  # Save image to HDF5 file\n",
    "\n",
    "        labels = df[1].values.astype(int)\n",
    "        print(f\"Min label {min(labels)}, Max {max(labels)}\")\n",
    "        np.save(f\"{uid}.npy\", labels)\n",
    "    h.close()\n",
    "    print(f\"Saved to {uid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
